---
title: "mtcars"
author: "Nusa Seldi"
format: gfm
editor: visual
toc: true
---

## Introduction

Motor Trend Car Road Tests (mtcars) contains the data from *Motor Trend* US magazine about fuel consumption and other aspects of automobile design and performance for 32 automobiles (1973-74 models).

This time, our goal is to predict the Miles per gallon (mpg) of 32 automobiles. We will utilize tidymodels' workflow_set function to build several regression models at once: linear model, support vector machine, and xgboost.

## Import Library

```{r}
#| warning: false

library(tidyverse)
library(tidymodels)
library(skimr)
```

## Load the data

```{r}
car_df <- mtcars

glimpse(car_df)
skim(car_df)
```

It can be seen that the dataset consists of 32 automobiles with 11 variables. All data types are numeric and there are no missing values in the dataset.

## Preprocessing

For preprocessing, we will change two variables, am (transmission) and vs (engine). We will transform the format to factor and also change the labels of the values.

```{r}
car_df <- car_df |> 
  mutate( am = case_match(am, 1 ~ "manual", .default = 'automatic'),
          vs = case_match(vs, 1 ~ 'straight', .default = 'v-shaped'),
          am = as.factor(am),
          vs = as.factor(vs))

```

## Explore the data

```{r}
#| echo: false
#| warning: false

car_df |> 
  ggplot(aes(x = hp, y = mpg)) +
  geom_point(color = "navy") +
  geom_smooth() +
  labs(title = "hp and mpg connection")

car_df |> 
  ggplot(aes(x = cyl, y = mpg)) +
  geom_point() +
  labs(title = "cyl and mpg connection")

car_df |> 
  ggplot(aes(mpg)) +
  geom_histogram(bins = 25) +
  labs(title = "Distribution of mpg")

car_df |> 
  ggplot(aes(am, mpg)) +
  geom_boxplot() +
  labs(title = "Transmission and mpg connection")

car_df |> 
  ggplot(aes(vs, mpg)) +
  geom_boxplot() +
  labs(title = "Engine and mpg connection")
```

## Build a Model

Before we build a model, we will divide the data into training set and test set with a ratio of 80:20. For feature engineering, we will normalize the data for numeric data and create dummy variables for nominal data.

```{r}
#| warning: false

set.seed(11)
car_split <- initial_split(car_df, prop = 0.8)
car_train <- training(car_split)
car_test <- testing(car_split)

set.seed(80)
car_fold <- bootstraps(car_train, times = 10)

car_recipe <- recipe(mpg ~ ., data = car_train) |> 
  step_normalize(all_numeric_predictors()) |> 
  step_dummy(all_nominal_predictors())

lm_spec <- linear_reg() |> 
  set_mode('regression') |> 
  set_engine('stan')

xgb_spec <- boost_tree() |> 
  set_mode('regression') |> 
  set_engine('xgboost')

svm_spec <- svm_linear() |> 
  set_mode('regression') |> 
  set_engine('kernlab')

wf_set <- workflow_set(preproc = list(basic = car_recipe),
                       models = list(lm = lm_spec,
                                     xgboost = xgb_spec,
                                     svm = svm_spec))

wf_set_fit <- workflow_map(wf_set,
                           resamples = car_fold,
                           seed = 123,
                           control = control_grid(save_pred = TRUE, save_workflow = TRUE ,parallel_over = "everything"))


```

## Evaluate the model

For the evaluation, we will use metric *rmse* to estimate our model performance. From the three models, we choose the best model according to metric rmse and fit the final model to the training set and evaluate the test set.

```{r}
wf_set_fit |> collect_metrics(summarize = T) 

wf_set_fit |> 
  rank_results() |> 
  filter(.metric == 'rmse')

autoplot(wf_set_fit, rank_metric = 'rmse', metric = 'rmse', select_best = TRUE)

best_result <- wf_set_fit |> 
  extract_workflow_set_result(id = 'basic_xgboost') |> 
  select_best(metric = 'rmse')

xgboost_result <- wf_set_fit |> 
  extract_workflow('basic_xgboost') |> 
  finalize_workflow(best_result) |> 
  last_fit(split = car_split)

collect_metrics(xgboost_result) 

predicted <- xgboost_result |> 
  collect_predictions()

predicted |> 
  select(.pred, mpg)

predicted |> 
  ggplot(aes(x = mpg, y = .pred)) +
  geom_point() +
  geom_abline(lty = 2) +
  coord_obs_pred()


```
